{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238a72ad",
   "metadata": {},
   "source": [
    "\n",
    "# Rocket League Match Winner Predictor (Rebuilt)\n",
    "\n",
    "This notebook trains a **no‑leak match‑winner predictor** using your two CSVs:\n",
    "\n",
    "- `matches_by_teams.csv` — per-team stats per match (includes `winner`)\n",
    "- `main.csv` — match/game metadata with a date column\n",
    "\n",
    "**Design choices:**\n",
    "- Uses **only past data** via `shift(1)` + rolling means\n",
    "- Builds **match‑level features** by subtracting Team B from Team A\n",
    "- **Time‑ordered** 80/20 split for evaluation\n",
    "- Trains **Logistic Regression** (with scaling) and **Random Forest**\n",
    "- Saves artifacts for reuse (`rl_match_predictor.pkl`, `test_set_predictions.csv`)\n",
    "- Includes an **inference helper** (predict probability for two teams as of a date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports & Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Ready. pandas:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1038bb",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Load Data (adjust paths if needed)\n",
    "matches_path = 'matches_by_teams.csv'\n",
    "main_path    = 'main.csv'\n",
    "\n",
    "matches = pd.read_csv(matches_path)\n",
    "main    = pd.read_csv(main_path)\n",
    "\n",
    "print(\"matches shape:\", matches.shape)\n",
    "print(\"main shape:\", main.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d14861c",
   "metadata": {},
   "source": [
    "## Dates & Per-Match Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b243fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Dates & Per-Match Metadata\n",
    "date_col = 'game_date' if 'game_date' in main.columns else ('match_date' if 'match_date' in main.columns else None)\n",
    "if date_col is None:\n",
    "    raise ValueError(\"No date column found in main.csv. Expected 'game_date' or 'match_date'.\")\n",
    "\n",
    "main[date_col] = pd.to_datetime(main[date_col], errors='coerce', utc=True)\n",
    "\n",
    "meta_candidates = ['match_id', date_col, 'event', 'event_region', 'event_tier',\n",
    "                   'match_format', 'stage', 'stage_is_lan', 'stage_is_qualifier']\n",
    "meta_cols = [c for c in meta_candidates if c in main.columns]\n",
    "\n",
    "main_match = (main.sort_values([date_col, 'match_id'])\n",
    "                  .drop_duplicates(subset=['match_id'], keep='first')[meta_cols])\n",
    "\n",
    "main_match.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa40da",
   "metadata": {},
   "source": [
    "## Per-Team Rows & Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Per-Team Rows & Feature Selection\n",
    "team_cols_pref = ['match_id','team_id','team_slug','team_name','team_region','color','winner']\n",
    "team_cols = [c for c in team_cols_pref if c in matches.columns]\n",
    "if 'match_id' not in team_cols or 'team_id' not in team_cols:\n",
    "    raise ValueError(\"Expected 'match_id' and 'team_id' in matches_by_teams.csv.\")\n",
    "\n",
    "# Auto-select numeric features (exclude ids/target)\n",
    "exclude_exact = {'match_id','team_id','winner'}\n",
    "numeric_cols = [c for c in matches.columns\n",
    "                if c not in exclude_exact and np.issubdtype(matches[c].dtype, np.number)]\n",
    "\n",
    "# Prefer typical RL stat families; fall back to all numeric if none match\n",
    "preferred_prefixes = ['core_', 'boost_', 'movement_', 'positioning_', 'demo_']\n",
    "rl_like = [c for c in numeric_cols if any(c.startswith(p) for p in preferred_prefixes)]\n",
    "feature_candidates = rl_like if rl_like else numeric_cols\n",
    "if len(feature_candidates) == 0:\n",
    "    raise ValueError(\"No usable numeric feature columns found in matches_by_teams.csv.\")\n",
    "\n",
    "print(f\"Using {len(feature_candidates)} numeric features (first 12): {sorted(feature_candidates)[:12]}\")\n",
    "\n",
    "# Build per_team INCLUDING feature columns\n",
    "per_team = matches[team_cols + feature_candidates].copy()\n",
    "\n",
    "# Normalize winner to 0/1\n",
    "if 'winner' in per_team.columns:\n",
    "    per_team['winner'] = per_team['winner'].astype(int) if per_team['winner'].dtype != bool else per_team['winner'].astype(int)\n",
    "else:\n",
    "    raise ValueError(\"Target column 'winner' missing in matches_by_teams.csv.\")\n",
    "\n",
    "# Attach date/meta and sort\n",
    "per_team = (per_team.merge(main_match, on='match_id', how='left')\n",
    "                    .sort_values(['team_id', date_col])\n",
    "                    .reset_index(drop=True))\n",
    "\n",
    "per_team.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9401a",
   "metadata": {},
   "source": [
    "## Rolling (Past-Only) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a79a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Rolling (Past-Only) Features\n",
    "ROLL_N = 5\n",
    "\n",
    "def _roll_mean(s):\n",
    "    # last N matches BEFORE current match\n",
    "    return s.shift(1).rolling(ROLL_N, min_periods=1).mean()\n",
    "\n",
    "roll_frames = []\n",
    "for col in feature_candidates:\n",
    "    r = (per_team.groupby('team_id')[col]\n",
    "         .apply(_roll_mean)\n",
    "         .rename(f'{col}_roll{ROLL_N}_mean'))\n",
    "    roll_frames.append(r)\n",
    "\n",
    "rolled = pd.concat(roll_frames, axis=1).reset_index(level=0, drop=True)\n",
    "per_team_rolled = pd.concat([per_team, rolled], axis=1)\n",
    "\n",
    "roll_cols = [c for c in per_team_rolled.columns if c.endswith(f'_roll{ROLL_N}_mean')]\n",
    "per_team_rolled[roll_cols] = per_team_rolled[roll_cols].fillna(per_team_rolled[roll_cols].mean())\n",
    "\n",
    "print(f\"Built {len(roll_cols)} rolling features over last {ROLL_N} matches.\")\n",
    "per_team_rolled[roll_cols].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4540330",
   "metadata": {},
   "source": [
    "## Build Match-Level Examples (Team A − Team B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Build Match-Level Examples (Team A − Team B)\n",
    "def build_pairs(df, date_col, roll_cols):\n",
    "    rows = []\n",
    "    for mid, grp in df.groupby('match_id', sort=False):\n",
    "        if len(grp) != 2:\n",
    "            continue\n",
    "        sort_key = 'team_name' if 'team_name' in grp.columns else 'team_id'\n",
    "        grp = grp.sort_values(sort_key)\n",
    "        a, b = grp.iloc[0], grp.iloc[1]\n",
    "        diff = a[roll_cols].values - b[roll_cols].values\n",
    "        y = int(a['winner'])  # whether Team A (alphabetical) won\n",
    "        rows.append((diff, y, {\n",
    "            'match_id': mid,\n",
    "            'date': a[date_col],\n",
    "            'teamA_id': a['team_id'],\n",
    "            'teamA_name': a.get('team_name', str(a['team_id'])),\n",
    "            'teamB_id': b['team_id'],\n",
    "            'teamB_name': b.get('team_name', str(b['team_id']))\n",
    "        }))\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(), np.array([]), pd.DataFrame()\n",
    "\n",
    "    X = np.vstack([r[0] for r in rows])\n",
    "    y = np.array([r[1] for r in rows])\n",
    "    meta_df = pd.DataFrame([r[2] for r in rows])\n",
    "    X_df = pd.DataFrame(X, columns=[f'diff__{c}' for c in roll_cols])\n",
    "    return X_df, y, meta_df\n",
    "\n",
    "X_df, y_vec, meta_df = build_pairs(per_team_rolled, date_col, roll_cols)\n",
    "if X_df.empty:\n",
    "    raise RuntimeError(\"No valid matches with exactly two teams found after processing.\")\n",
    "\n",
    "data = pd.concat([meta_df.reset_index(drop=True), X_df.reset_index(drop=True)], axis=1)\n",
    "data = data.dropna(subset=['date']).sort_values('date').reset_index(drop=True)\n",
    "data['label'] = y_vec.astype(int)\n",
    "feature_cols = [c for c in data.columns if c.startswith('diff__')]\n",
    "\n",
    "print(f\"Final training rows: {len(data)} | Features per row: {len(feature_cols)}\")\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b806f817",
   "metadata": {},
   "source": [
    "## Train/Test Split, Train Models, Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c27e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Train/Test Split, Train Models, Evaluate\n",
    "split_idx = int(len(data) * 0.80)\n",
    "train_df = data.iloc[:split_idx].copy()\n",
    "test_df  = data.iloc[split_idx:].copy()\n",
    "\n",
    "X_train, y_train = train_df[feature_cols].values, train_df['label'].values\n",
    "X_test,  y_test  = test_df[feature_cols].values,  test_df['label'].values\n",
    "\n",
    "logreg = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000))])\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_split=4, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(name, model):\n",
    "    yhat_tr = model.predict(X_train)\n",
    "    yhat_te = model.predict(X_test)\n",
    "    proba_tr = model.predict_proba(X_train)[:,1]\n",
    "    proba_te = model.predict_proba(X_test)[:,1]\n",
    "    return {\n",
    "        'model': name,\n",
    "        'train_acc': accuracy_score(y_train, yhat_tr),\n",
    "        'test_acc':  accuracy_score(y_test,  yhat_te),\n",
    "        'train_auc': roc_auc_score(y_train, proba_tr),\n",
    "        'test_auc':  roc_auc_score(y_test,  proba_te),\n",
    "        'train_logloss': log_loss(y_train, proba_tr),\n",
    "        'test_logloss':  log_loss(y_test,  proba_te)\n",
    "    }, (yhat_te, proba_te)\n",
    "\n",
    "r1, (yhat_log_te, proba_log_te) = evaluate('LogisticRegression', logreg)\n",
    "r2, (yhat_rf_te,  proba_rf_te)  = evaluate('RandomForest', rf)\n",
    "\n",
    "perf = pd.DataFrame([r1, r2]).round(4)\n",
    "perf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab2f8f5",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Plots\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, proba_log_te, name='LogReg')\n",
    "RocCurveDisplay.from_predictions(y_test, proba_rf_te,  name='RandomForest')\n",
    "plt.title('ROC Curve (Test)')\n",
    "plt.show()\n",
    "\n",
    "best_name = 'LogisticRegression' if r1['test_auc'] >= r2['test_auc'] else 'RandomForest'\n",
    "best_pred = yhat_log_te if best_name == 'LogisticRegression' else yhat_rf_te\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, best_pred)\n",
    "plt.title(f'Confusion Matrix - {best_name} (Test)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c91859",
   "metadata": {},
   "source": [
    "## Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9) Save Artifacts\n",
    "best_model = logreg if r1['test_auc'] >= r2['test_auc'] else rf\n",
    "artifact = {\n",
    "    'model_name': 'LogisticRegression' if r1['test_auc'] >= r2['test_auc'] else 'RandomForest',\n",
    "    'model': best_model,\n",
    "    'feature_cols': feature_cols,\n",
    "    'roll_cols': roll_cols,\n",
    "    'roll_window': 5,\n",
    "    'built_on': datetime.utcnow().isoformat() + 'Z'\n",
    "}\n",
    "with open('rl_match_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump(artifact, f)\n",
    "\n",
    "out_preds = test_df[['match_id','date','teamA_name','teamB_name','label']].copy()\n",
    "out_preds['prob_A_wins'] = best_model.predict_proba(test_df[feature_cols].values)[:,1]\n",
    "out_preds.rename(columns={'label':'actual_A_won'}, inplace=True)\n",
    "out_preds.to_csv('test_set_predictions.csv', index=False)\n",
    "\n",
    "print(\"Saved -> rl_match_predictor.pkl\")\n",
    "print(\"Saved -> test_set_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414e881",
   "metadata": {},
   "source": [
    "## Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b52232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10) Inference Helper\n",
    "def _latest_roll_for_team(team_name, as_of=None):\n",
    "    df = per_team_rolled.copy()\n",
    "    if as_of is not None:\n",
    "        as_of = pd.to_datetime(as_of, utc=True)\n",
    "        df = df[df['game_date' if 'game_date' in df.columns else 'match_date'] < as_of]\n",
    "    rows = df[df['team_name'] == team_name].sort_values('game_date' if 'game_date' in df.columns else 'match_date')\n",
    "    if rows.empty:\n",
    "        return None\n",
    "    return rows.iloc[-1][roll_cols].values\n",
    "\n",
    "def predict_match_prob(teamA_name, teamB_name, as_of=None):\n",
    "    vecA = _latest_roll_for_team(teamA_name, as_of=as_of)\n",
    "    vecB = _latest_roll_for_team(teamB_name, as_of=as_of)\n",
    "    if vecA is None or vecB is None:\n",
    "        raise ValueError(\"Missing history for one or both teams before the given date.\")\n",
    "    diff = (vecA - vecB).reshape(1, -1)\n",
    "    diff_df = pd.DataFrame(diff, columns=roll_cols)\n",
    "    X = diff_df.rename(columns={c: f'diff__{c}' for c in roll_cols})[artifact['feature_cols']].values\n",
    "    return float(artifact['model'].predict_proba(X)[:,1])\n",
    "\n",
    "# Example (adjust names/date to your dataset):\n",
    "# predict_match_prob('G2 ESPORTS', 'NRG', as_of='2022-06-01')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
